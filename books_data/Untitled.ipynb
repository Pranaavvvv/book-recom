{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d74b94-26c3-4180-a79d-d133fe23e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from typing import List, Tuple\n",
    "\n",
    "class BookRecommender:\n",
    "    def __init__(self):\n",
    "        self.books_df = None\n",
    "        self.tfidf_matrix = None\n",
    "        self.cosine_sim = None\n",
    "        self.indices = None\n",
    "    \n",
    "    def load_and_preprocess_data(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load and preprocess the books dataset\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read CSV file with error handling\n",
    "            self.books_df = pd.read_csv(file_path, \n",
    "                                         sep=';', \n",
    "                                         encoding='ISO-8859-1',  # Changed encoding to ISO-8859-1 to avoid decoding issues\n",
    "                                         quoting=1,  # Handle quotes\n",
    "                                         escapechar='\\\\',       # Handle escape characters\n",
    "                                         on_bad_lines='skip')   # Skip bad lines\n",
    "            \n",
    "            # Clean column names\n",
    "            self.books_df.columns = self.books_df.columns.str.strip('\"')\n",
    "            \n",
    "            # Drop any rows with missing values\n",
    "            self.books_df = self.books_df.dropna(subset=['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication'])\n",
    "            \n",
    "            # Create a combined features column for TF-IDF\n",
    "            self.books_df['combined_features'] = self.books_df.apply(\n",
    "                lambda x: f\"{x['Book-Author']} {x['Publisher']} {x['Year-Of-Publication']}\", \n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            # Create TF-IDF matrix as a sparse matrix to save memory\n",
    "            tfidf = TfidfVectorizer(stop_words='english')\n",
    "            self.tfidf_matrix = tfidf.fit_transform(self.books_df['combined_features'])\n",
    "            \n",
    "            # Calculate cosine similarity matrix for sparse matrix\n",
    "            self.cosine_sim = cosine_similarity(self.tfidf_matrix, self.tfidf_matrix)\n",
    "            \n",
    "            # Create reverse mapping of book titles and indices\n",
    "            self.indices = pd.Series(\n",
    "                self.books_df.index, \n",
    "                index=self.books_df['Book-Title']\n",
    "            ).drop_duplicates()\n",
    "            \n",
    "            print(f\"Successfully loaded {len(self.books_df)} books.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def get_recommendations(self, title: str, n_recommendations: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get book recommendations based on title similarity\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get the index of the book\n",
    "            idx = self.indices[title]\n",
    "            \n",
    "            # Get similarity scores for all books\n",
    "            sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "            \n",
    "            # Sort books based on similarity scores\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Get top N most similar books (excluding the input book)\n",
    "            sim_scores = sim_scores[1:n_recommendations + 1]\n",
    "            \n",
    "            # Get book indices and similarity scores\n",
    "            book_indices = [i[0] for i in sim_scores]\n",
    "            similarity_scores = [i[1] for i in sim_scores]\n",
    "            \n",
    "            # Return recommended books with their similarity scores\n",
    "            recommendations = [\n",
    "                (self.books_df['Book-Title'].iloc[i], score) \n",
    "                for i, score in zip(book_indices, similarity_scores)\n",
    "            ]\n",
    "            \n",
    "            return recommendations\n",
    "            \n",
    "        except KeyError:\n",
    "            return [(\"Book not found in database\", 0.0)]\n",
    "    \n",
    "    def get_book_details(self, title: str) -> dict:\n",
    "        \"\"\"\n",
    "        Get detailed information about a specific book\n",
    "        \"\"\"\n",
    "        try:\n",
    "            book_info = self.books_df[self.books_df['Book-Title'] == title].iloc[0]\n",
    "            return {\n",
    "                'Title': book_info['Book-Title'],\n",
    "                'Author': book_info['Book-Author'],\n",
    "                'Year': book_info['Year-Of-Publication'],\n",
    "                'Publisher': book_info['Publisher'],\n",
    "                'ISBN': book_info['ISBN']\n",
    "            }\n",
    "        except IndexError:\n",
    "            return {\"Error\": \"Book not found in database\"}\n",
    "    \n",
    "    def get_author_recommendations(self, author: str, n_recommendations: int = 5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get recommendations for other books by the same author\n",
    "        \"\"\"\n",
    "        author_books = self.books_df[\n",
    "            self.books_df['Book-Author'].str.lower() == author.lower()\n",
    "        ]['Book-Title'].tolist()\n",
    "        \n",
    "        return author_books[:n_recommendations]\n",
    "    \n",
    "    def get_similar_by_year(self, year: int, n_recommendations: int = 5) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get recommendations for books published in the same year\n",
    "        \"\"\"\n",
    "        year_books = self.books_df[\n",
    "            self.books_df['Year-Of-Publication'] == str(year)\n",
    "        ]['Book-Title'].tolist()\n",
    "        \n",
    "        return year_books[:n_recommendations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd218a98-8ed9-4c53-ad33-15f8f0f39326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data: Unable to allocate 65.7 GiB for an array with shape (8821959009,) and data type int64\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 65.7 GiB for an array with shape (8821959009,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize and load data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m recommender \u001b[38;5;241m=\u001b[39m BookRecommender()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrecommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbooks.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 45\u001b[0m, in \u001b[0;36mBookRecommender.load_and_preprocess_data\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity matrix for sparse matrix\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_sim \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfidf_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Create reverse mapping of book titles and indices\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooks_df\u001b[38;5;241m.\u001b[39mindex, \n\u001b[0;32m     50\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbooks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBook-Title\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     51\u001b[0m )\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1687\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1687\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    203\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    208\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m ):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\sparse\\_base.py:669\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    668\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\sparse\\_base.py:580\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension mismatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[0;32m    583\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:550\u001b[0m, in \u001b[0;36m_cs_matrix._matmul_sparse\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    545\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    546\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[0;32m    547\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[0;32m    549\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[1;32m--> 550\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnnz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(nnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, other\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    553\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 65.7 GiB for an array with shape (8821959009,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Initialize and load data\n",
    "recommender = BookRecommender()\n",
    "recommender.load_and_preprocess_data('books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b3bde-4fbf-4dd1-90cf-b9c3367e838b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
